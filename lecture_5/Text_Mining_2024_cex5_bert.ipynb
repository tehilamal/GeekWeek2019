{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tehilamal/GeekWeek2019/blob/master/lecture_5/Text_Mining_2024_cex5_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRBvs_jJcnsP"
      },
      "source": [
        "# CE5: BERT and Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxupzgqUcnsQ"
      },
      "source": [
        "## 0. Dataset and Baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1741WfsacnsQ"
      },
      "outputs": [],
      "source": [
        "# basic imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MFkBeK1cnsR"
      },
      "source": [
        "### 0.1. Dataset\n",
        "\n",
        "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
        "\n",
        "\n",
        "<table class=\"features-table\">\n",
        "  <tr>\n",
        "    <th class=\"mdc-text-light-green-600\">\n",
        "    sentence\n",
        "    </th>\n",
        "    <th class=\"mdc-text-purple-600\">\n",
        "    label\n",
        "    </th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      apparently reassembled from the cutting room floor of any given daytime soap\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      they presume their audience won't sit still for a sociology lesson\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      0\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
        "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
        "    </td>\n",
        "    <td class=\"mdc-bg-purple-50\">\n",
        "      1\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "**SST2 on HuggingFace:**\n",
        "\n",
        "https://huggingface.co/datasets/stanfordnlp/sst2\n",
        "\n",
        "**More on SST2:**\n",
        "\n",
        "The Stanford Sentiment Treebank is a corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language. The corpus is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from movie reviews. It was parsed with the Stanford parser and includes a total of 215,154 unique phrases from those parse trees, each annotated by 3 human judges.\n",
        "\n",
        "Binary classification experiments on full sentences (negative or somewhat negative vs somewhat positive or positive with neutral sentences discarded) refer to the dataset as SST-2 or SST binary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LILSswkAcnsR"
      },
      "source": [
        "#### 0.1.1. Importing the dataset\n",
        "We'll use pandas to read the dataset and load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cStfAMm4cnsS"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KAPk2vmpcnsS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(dataset_url, delimiter='\\t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_0Rr0ABmcnsS"
      },
      "outputs": [],
      "source": [
        "sentences = df[0]\n",
        "labels = df[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences.head(), labels.head()"
      ],
      "metadata": {
        "id": "XHfimxtTdg-L",
        "outputId": "2e8299eb-3332-48c8-a4e1-1613feb04170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    a stirring , funny and finally transporting re...\n",
              " 1    apparently reassembled from the cutting room f...\n",
              " 2    they presume their audience wo n't sit still f...\n",
              " 3    this is a visually stunning rumination on love...\n",
              " 4    jonathan parker 's bartleby should have been t...\n",
              " Name: 0, dtype: object,\n",
              " 0    1\n",
              " 1    0\n",
              " 2    0\n",
              " 3    1\n",
              " 4    1\n",
              " Name: 1, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEXueZsmcnsS"
      },
      "source": [
        "For performance reasons, we'll only use 2,000 sentences from the dataset when using BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sw8v1Q3lcnsS"
      },
      "outputs": [],
      "source": [
        "subdf = df[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UIA4uZxlcnsS"
      },
      "outputs": [],
      "source": [
        "sub_sentences = subdf[0]\n",
        "sub_labels = subdf[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM_7ZyEYcnsS"
      },
      "source": [
        "Let's see how many sentences are labeled as having a positive sentiment (value 1) and how many are labeled with negative sentiment (value 0):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AsVlBkfXcnsS",
        "outputId": "47d2a7bd-71ff-4ac6-91aa-41e26f06e434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1\n",
              "1    1041\n",
              "0     959\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "subdf[1].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWV2Vm4xcnsS"
      },
      "source": [
        "#### 0.1.2. Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L43NPNc3cnsS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9OVbi9dcnsS"
      },
      "source": [
        "##### Q1: Split the sentence and labels to train and test sets\n",
        "\n",
        "Then do the same for `sub_sentences` and  `sub_labels`.\n",
        "\n",
        "**Hint:** Look at `sklearn`'s `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sub_sentences_train, sub_sentences_test, sub_sentences_train, sub_sentences_test = train_test_split(sub_sentences, sub_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mL8i1LrZd8zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCENz87UcnsS"
      },
      "source": [
        "### 0.2. Baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQTJCIcqcnsS"
      },
      "source": [
        "#### 0.2.0. The Dummy Classifier\n",
        "\n",
        "DummyClassifier makes predictions that ignore the input features.\n",
        "\n",
        "This classifier serves as a simple baseline to compare against other more complex classifiers.\n",
        "\n",
        "https://scikit-learn.org/1.5/modules/generated/sklearn.dummy.DummyClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5sBBIMecnsT"
      },
      "source": [
        "##### Q2: Use sklearn's dummy classifier as a baseline\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Use sklearn's dummy classifier as a baseline\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming sub_sentences_train, sub_sentences_test, sub_labels_train, sub_labels_test are defined as in the original code.\n",
        "# If not, replace with your actual train/test split.\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(sub_sentences_train, sub_labels_train) # Fit the dummy classifier\n",
        "dummy_predictions = dummy_clf.predict(sub_sentences_test) # Make predictions\n",
        "dummy_accuracy = accuracy_score(sub_labels_test, dummy_predictions)\n",
        "print(f\"Dummy classifier accuracy: {dummy_accuracy}\")"
      ],
      "metadata": {
        "id": "7RXKYzPCekrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkXlR9CRcnsT"
      },
      "source": [
        "#### 0.2.1. LogReg w/ BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VeC3oSpncnsT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2IdDga9tcnsT"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer for Bag-of-Words model\n",
        "vectorizer = CountVectorizer(max_features=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca2bCtVwcnsT"
      },
      "source": [
        "##### Q3: Complete the BoW-based baseline\n",
        "\n",
        "What accuracy does it achieve on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB4MZtAqcnsT"
      },
      "source": [
        "#### 0.2.2. LogReg w/ Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WCUs3eOvcnsT"
      },
      "outputs": [],
      "source": [
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IgSg1SRYcnsT"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUgtZeEVcnsT",
        "outputId": "0e072879-46e2-4fe0-c817-36f262176e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 98.7% 748.4/758.5MB downloaded"
          ]
        }
      ],
      "source": [
        "glove_embedder = gensim.downloader.load('glove-twitter-200')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbQGBf6EcnsT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def document_to_vector(document, model):\n",
        "    token_list = gensim.utils.simple_preprocess(document)\n",
        "    vector_list = []\n",
        "    for token in token_list:\n",
        "        try:\n",
        "            vector_list.append(model[token])\n",
        "        except KeyError:\n",
        "            pass\n",
        "    return np.average(vector_list, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58Hk45SDcnsT"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def vector_list_to_sparse_matrix(vector_list):\n",
        "    dense_matrix = np.stack(vector_list)\n",
        "    return csr_matrix(dense_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15u31zZQcnsT"
      },
      "outputs": [],
      "source": [
        "def sentence_list_to_sparse_embeddings(sentence_list, embedding_model):\n",
        "    vector_list = [document_to_vector(sent, embedding_model) for sent in sentence_list]\n",
        "    return vector_list_to_sparse_matrix(vector_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2N_9S2KcnsT"
      },
      "outputs": [],
      "source": [
        "# Transform text data\n",
        "train_glove_vectors = sentence_list_to_sparse_embeddings(train_sentences, glove_embedder)\n",
        "test_glove_vectors = sentence_list_to_sparse_embeddings(test_sentences, glove_embedder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gLQrrKEcnsT"
      },
      "outputs": [],
      "source": [
        "lr_glove_clf = LogisticRegression()\n",
        "lr_glove_clf.fit(train_glove_vectors, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcvIStGGcnsT"
      },
      "outputs": [],
      "source": [
        "lr_glove_clf.score(test_glove_vectors, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtaAtL8-cnsT"
      },
      "source": [
        "## 1. (Old School) DistilBERT for Sentence Classification\n",
        "\n",
        "Let's use a pretrained BERT(-like) model for sentiment classification.\n",
        "\n",
        "We will use DistilBERT, a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
        "\n",
        "First, we will use it in the way the BERT paper suggested document vectors should be extracted from BERT for text classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5EBXo-cnsU"
      },
      "source": [
        "### 1.1. Installing the transformers library\n",
        "\n",
        "Let's start by installing the huggingface transformers library so we can load pre-trained transformer models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To9ENLU90WGl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnaonZG0cnsU"
      },
      "source": [
        "### 1.2. Library imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGv5sxJncnsU"
      },
      "outputs": [],
      "source": [
        "# On Colab, run:\n",
        "# %tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# transformers and related packages\n",
        "import transformers\n",
        "import torch  # pytorch, perhaps THE deep learning framework in Python (but see also Keras and TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "### 1.3. Loading the Pre-trained BERT model\n",
        "Let's now load a pre-trained BERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1InADgf5xm2"
      },
      "outputs": [],
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (transformers.DistilBertModel, transformers.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model and tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "embedder = model_class.from_pretrained(pretrained_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDBMn3wiSX6"
      },
      "source": [
        "### 1.4. Preprocessing\n",
        "Before we can hand our sentences to BERT, we need to do some minimal processing to put them in the format it requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdgO-JNHcnsY"
      },
      "outputs": [],
      "source": [
        "def bert_preprocess_sentence_list(sent_list):\n",
        "    # 1 - Tokenization\n",
        "    tokenized = sent_list.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "    # 2 - Padding\n",
        "    # After tokenization, `tokenized` is a list of sentences -- each sentences is represented\n",
        "    # as a list of tokens. We want BERT to process our examples all at once (as one batch).\n",
        "    # It's just faster that way.\n",
        "    # For that reason, we need to pad all lists to the same size, so we can represent the\n",
        "    # input as one 2-d array,\n",
        "    # rather than a list of lists (of different lengths).\n",
        "    max_len = 0\n",
        "    for i in tokenized.values:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "    # print(\"Shape after padding:\")\n",
        "    # print(np.array(padded).shape)\n",
        "    # 3 - Masking\n",
        "    # If we directly send `padded` to BERT, that would slightly confuse it.\n",
        "    # We need to create another variable to tell it to ignore (mask) the padding\n",
        "    # we've added when it's processing its input. That's what attention_mask is:\n",
        "    attention_mask = np.where(padded != 0, 1, 0)\n",
        "    # attention_mask.shape\n",
        "    return padded, attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-CQB9-kN99"
      },
      "source": [
        "### 1.5. Embedding our sentences\n",
        "\n",
        "\n",
        "The `embedder()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "Like suggested in the original paper, we willslice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9t60At16PVs"
      },
      "outputs": [],
      "source": [
        "def preprocessed_vectors_to_embeddings(padded, attention_mask):\n",
        "    input_ids = torch.tensor(padded)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = embedder(input_ids, attention_mask=attention_mask)\n",
        "    # taking only the [CLS] vector\n",
        "    features = last_hidden_states[0][:,0,:].numpy()\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4t7szKccnsY"
      },
      "source": [
        "##### Q4: Define the sentenece_list_to_bert_cls_embeddings function\n",
        "\n",
        "**Hint**: Use the two functions pre-defined above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rk34jQ0cnsY"
      },
      "source": [
        "##### Q5: Get the DistilBERT embeddings for our case\n",
        "\n",
        "Populate `distilbert_train_vectors` and `distilbert_test_vectors`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCs00XCkcnsY"
      },
      "source": [
        "### 1.6. Train and evaluate an LR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG-EVWx4CzBc"
      },
      "outputs": [],
      "source": [
        "bert_lr_clf = LogisticRegression()\n",
        "bert_lr_clf.fit(distilbert_train_vectors, sub_train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCoyxRJ7ECTA"
      },
      "outputs": [],
      "source": [
        "bert_lr_clf.score(distilbert_test_vectors, sub_test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQuqV6cnWQu"
      },
      "source": [
        "**What would we usually do to improve performance?**\n",
        "\n",
        "1. More sophisticated classification models (if you have enogh data, a deep learning model).\n",
        "2. Different embedding models.\n",
        "3. If we have a large enough labeled dataset, [fine-tuning](https://huggingface.co/transformers/examples.html#glue)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDCJ6h_YcnsY"
      },
      "source": [
        "## 2. Modern Usage of the Transformers package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C17LUObDcnsY"
      },
      "source": [
        "This example will demonstrate two things:\n",
        "1. The modern, streamlined way to use the `transformers` package.\n",
        "2. Using a model pretrained for a specific case (rather than training a new model on pre-trained word/document embeddings)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlwZTLTccnsY"
      },
      "source": [
        "### 2.1. Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aayOSAwEcnsY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "import numpy as np\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P-x3Ma-cnsZ"
      },
      "source": [
        "### 2.2. Loading the pretrained tokenized, model and configuration\n",
        "\n",
        "We will use a highly popular (on HuggingFace) model for sentiment analyasis:\n",
        "\n",
        "Twitter-roBERTa-base for Sentiment Analysis\n",
        "\n",
        "It was finetuned to do well for sentiment analysis of tweets (with the TweetEval benchmark in mind).\n",
        "Let's see how it fares on movie sentiment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uxm89iPcnsZ"
      },
      "outputs": [],
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXYpTPTLcnsZ"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLI4yiekcnsZ"
      },
      "source": [
        "### 2.3. Usage example for a single text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM6WUsfEcnsZ"
      },
      "outputs": [],
      "source": [
        "# example on a single text\n",
        "text = \"Covid cases are increasing fast!\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "# Print labels and scores\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = config.id2label[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scUX40btcnsZ"
      },
      "source": [
        "### 2.4. A nice prediction function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnOeI90fcnsZ"
      },
      "source": [
        "##### Q6: Write get_roberta_sentiment_pred\n",
        "\n",
        "Define the `get_roberta_sentiment_pred` function, which gets a string (some text) and returns 1 our model detects a positive sentiment, and 0 otherwise.\n",
        "\n",
        "**Hint 1:** Use the code above as a basis.\n",
        "\n",
        "**Hint 2:** There are several different possible logics to write to get a binary (0/1) sentiment score based on the above trinary scores. Go wild!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsf3mamjcnsZ"
      },
      "outputs": [],
      "source": [
        "get_roberta_sentiment_pred(\"Covid cases are increasing fast!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3eOkA4dcnsZ"
      },
      "outputs": [],
      "source": [
        "get_roberta_sentiment_pred(\"This is so great!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxAvjgKicnsZ"
      },
      "source": [
        "### 2.5. Predict and Evaluate on our test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtOw4swJcnsZ"
      },
      "source": [
        "*(not an efficient way to do this, but I won't teach you the matricized way)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGrSFOKkcnsZ"
      },
      "outputs": [],
      "source": [
        "sub_test_preds = [get_roberta_sentiment_pred(sent) for sent in sub_test_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HllC9zpVcnsZ"
      },
      "outputs": [],
      "source": [
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(sub_test_labels, sub_test_preds)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX_NvJycnsZ"
      },
      "source": [
        "## 3. SST2 scores of other models\n",
        "\n",
        "https://paperswithcode.com/sota/sentiment-analysis-on-sst-2-binary\n",
        "\n",
        "For reference, the highest accuracy score for this dataset in the above benchmark is currently **97.5**, by\n",
        "T5-11B.\n",
        "\n",
        "However, it's pretty old; I assume there are better models out there: Papers With Code benchmarks only includes scores published in academic papers.\n",
        "\n",
        "DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task. The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "A Visual Notebook to Using BERT for the First Time.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}